{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Partial Data Loading with NPY, NPZ, and HDF5\n",
    "\n",
    "Many neuroscience experiments generate large data arrays—spike times, imaging data volumes, ephys timeseries, etc.—often gigabytes or terabytes in size. Selecting the right file format (and read strategy) can significantly reduce loading times and memory usage. Here, we compare three popular formats in Python:\n",
    "\n",
    "- **NPY** (single array in a raw binary format)\n",
    "- **NPZ** (a ZIP container of NPY files)\n",
    "- **HDF5** (a hierarchical, chunked container supporting partial reads, often used in large-scale neuroscience)\n",
    "\n",
    "In this notebook, we'll run measurements checking how long it takes to go from opening a file on disk to having the desired part of a single array in a Python variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps we plan to test:\n",
    "actions_list = [\n",
    "    'Open File',\n",
    "    'Get Data Variable',\n",
    "    'Slice All Variable into Memory',\n",
    "    'Slice Part of Variable into Memory'\n",
    "]\n",
    "\n",
    "# Set up a single-run timeit magic that returns a result object\n",
    "%alias_magic benchmark timeit -p \"-r1 -n1 -o\" --line\n",
    "\n",
    "# Generate large random test data\n",
    "a = np.random.random(size=(1_000_000, 100))\n",
    "print(\"Array Shape:\", a.shape)\n",
    "print(f\"Array Size in Memory: {a.nbytes / 1024**2 :.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Benchmark: NPY with `np.load()`\n",
    "\n",
    "The `np.load()` function is simple with `.npy` files: you call it and immediately get your numpy array into memory!  the downside is, if you only wanted to look at part of the array, you are forced to first read the entire array into memory. \n",
    "\n",
    "Here's the code we will test.  Notice that for `np.load()`, some actions have exactly the same code--this will be different for later tests.\n",
    "\n",
    "| Action                               | Benchmark Code                          |\n",
    "|--------------------------------------|-----------------------------------------|\n",
    "| Open File                            | `np.load('a.npy')`           |\n",
    "| Get Data Variable                    | `np.load('a.npy')`           |\n",
    "| Slice All Variable into Memory       | `np.load('a.npy')[:]`        |\n",
    "| Slice Part of Variable into Memory   | `np.load('a.npy')[:10000, 5:20]` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write test file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('a.npy', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Benchmark Tests on Reading from Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time the loading operations\n",
    "time_npy_openfile  = %benchmark np.load('a.npy')\n",
    "time_npy_getvar    = %benchmark np.load('a.npy')\n",
    "time_npy_sliceall  = %benchmark np.load('a.npy')[:]\n",
    "time_npy_slicepart = %benchmark np.load('a.npy')[:10000, 5:20]\n",
    "\n",
    "# Collect Times\n",
    "df_npy = pd.DataFrame({'Action': actions_list, 'Time': [\n",
    "    time_npy_openfile.average,\n",
    "    time_npy_getvar.average,\n",
    "    time_npy_sliceall.average,\n",
    "    time_npy_slicepart.average\n",
    "]})\n",
    "\n",
    "# Plot Results\n",
    "ax = sns.barplot(data=df_npy, x='Action', y='Time')\n",
    "ax.set(title='NPY Benchmark', ylabel='Time (s)')\n",
    "plt.xticks(rotation=30, ha='right');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Benchmark: NPZ\n",
    "\n",
    "`.npz` files also are read with the `np.load()` function, but they don't immediately read the whole file; instead, they return a collection of the names of variables stored in the file in order to ask you which variables you'd like to load.  This changes the performance of the code, and means that having more datasets in a file doesn't increase the reading time of the file!\n",
    "\n",
    "Here's the code we will test.  Notice that unlike for `.npy` files, `.npz` files can store many arrays, so you need you to reference the variable name stored in the file for the array you want to load.\n",
    "\n",
    "\n",
    "| Action                               | Benchmark Code                                 |\n",
    "|--------------------------------------|------------------------------------------------|\n",
    "| Open File                            | `np.load('a.npz')`                  |\n",
    "| Get Data Variable                    | `np.load('a.npz')['a']`             |\n",
    "| Slice All Variable into Memory       | `np.load('a.npz')['a'][:]`          |\n",
    "| Slice Part of Variable into Memory   | `np.load('a.npz')['a'][:10000, 5:20]` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('a.npz', a=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Benchmark Tests on Reading from Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time the loading operations\n",
    "time_npz_openfile  = %benchmark np.load('a.npz')\n",
    "time_npz_getvar    = %benchmark np.load('a.npz')['a']\n",
    "time_npz_sliceall  = %benchmark np.load('a.npz')['a'][:]\n",
    "time_npz_slicepart = %benchmark np.load('a.npz')['a'][:10000, 5:20]\n",
    "\n",
    "# Collect Times\n",
    "df_npz = pd.DataFrame({'Action': actions_list, 'Time': [\n",
    "    time_npz_openfile.average,\n",
    "    time_npz_getvar.average,\n",
    "    time_npz_sliceall.average,\n",
    "    time_npz_slicepart.average\n",
    "]})\n",
    "\n",
    "# Plot Results\n",
    "ax = sns.barplot(data=df_npz, x='Action', y='Time')\n",
    "ax.set(title='NPZ Benchmark', ylabel='Time (s)')\n",
    "plt.xticks(rotation=30, ha='right');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Benchmark: HDF5\n",
    "\n",
    "\n",
    "Below is a reference table for HDF5:\n",
    "\n",
    "| Action   | Benchmark Code    |\n",
    "|---------|-------------------------|\n",
    "| Open File                            | `f = h5py.File('a.h5')`      |\n",
    "| Get Data Variable                    | `f['a']` |\n",
    "| Slice All Variable into Memory       | `f['a'][:]`           |\n",
    "| Slice Part of Variable into Memory   | `f['a'][:10000, 5:20]`  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Write test file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('a.h5', 'w') as f:\n",
    "    f['a'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Benchmark Tests on Reading from Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the loading operations\n",
    "time_h5_openfile = %benchmark h5py.File('a.h5').close()\n",
    "\n",
    "with h5py.File('a.h5', 'r') as f:\n",
    "    time_h5_getvar    = %benchmark f['a']\n",
    "    time_h5_sliceall  = %benchmark f['a'][:]\n",
    "    time_h5_slicepart = %benchmark f['a'][:10000, 5:20]\n",
    "\n",
    "# Collect Times\n",
    "df_h5 = pd.DataFrame({'Action': actions_list, 'Time': [\n",
    "    time_h5_openfile.average,\n",
    "    time_h5_getvar.average,\n",
    "    time_h5_sliceall.average,\n",
    "    time_h5_slicepart.average\n",
    "]})\n",
    "\n",
    "\n",
    "# Plot Results\n",
    "ax = sns.barplot(data=df_h5, x='Action', y='Time')\n",
    "ax.set(title='HDF5 Benchmark', ylabel='Time (s)')\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Combined Comparison\n",
    "\n",
    "Let's combine the results from all the tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npy['Format'] = 'NPY'\n",
    "df_npz['Format'] = 'NPZ'\n",
    "df_h5['Format'] = 'HDF5'\n",
    "\n",
    "df_all = pd.concat([df_npy, df_npz, df_h5], ignore_index=True)\n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and plot the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df_all, x='Format', y='Time', hue='Action')\n",
    "ax.set(ylabel='Time (s)', title='Combined Benchmark: NPY vs NPZ vs HDF5')\n",
    "ax.legend(bbox_to_anchor=(1, 1));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- **NPY**: Best for storing single arrays, quick to load everything at once. If your dataset is not massive, or you always need the entire array in memory, NPY can be sufficient and easy.  \n",
    "- **NPZ**: Can store multiple arrays in one container. Great for distributing small to moderate collections of arrays, but it often unzips and loads large data fully, so partial reads aren’t a big advantage here.  \n",
    "- **HDF5**: Highly recommended for large-scale neuroscience data (e.g., multi-gigabyte or terabyte-level recordings in ephys, calcium imaging movies, etc.). With h5py, you can:\n",
    "  - Store multiple named datasets in a single file, mimicking a file system hierarchy (`f['my_neuron_data']`, `f['stimulus']`, etc.).\n",
    "  - Load only the specific slices or channels you need (saves memory and speeds up analysis for partial reads).\n",
    "  - Potentially use chunking and compression options to optimize read performance for your specific use-case.\n",
    "\n",
    "In real-world neuroscientific workflows—where data can be huge (e.g., weeks-long continuous recordings, thousands of channels, volumetric imaging stacks)—HDF5’s partial reading avoids the memory overload and time cost of reading massive arrays you don’t fully need.\n",
    "\n",
    "When choosing a file format for large data arrays in neuroscience, **HDF5** stands out by offering partial loading, chunking, and hierarchical organization. Although opening an HDF5 file has some initial overhead, it pays off if you only need to read part of a large dataset repeatedly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
